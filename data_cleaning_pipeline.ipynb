{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install faker\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbb5fYpNYBrn",
        "outputId": "7a36b1a2-7fba-47fe-f939-faca20b071d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "# Initialize the Faker instance\n",
        "fake = Faker()\n",
        "\n",
        "# Step 1: Generate Messy Data (using Faker to simulate real-world data issues)\n",
        "def generate_messy_data(num_records=100):\n",
        "    \"\"\"Generate a messy dataset with random missing values, inconsistent formats, and duplicates.\"\"\"\n",
        "    records = []\n",
        "    for _ in range(num_records):\n",
        "        records.append({\n",
        "            'ID': random.choice([fake.unique.random_int(min=1, max=100), np.nan, \"\"]),\n",
        "            'Name': random.choice([fake.name(), None, \" \"]),\n",
        "            'Age': random.choice([fake.random_int(min=18, max=60), np.nan, \"Unknown\"]),\n",
        "            'Join Date': random.choice([fake.date(), fake.date(pattern='%d-%m-%Y'), fake.date(pattern='%m/%d/%Y'), np.nan, \"Invalid\"])\n",
        "        })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "# Step 2: Identify issues (Missing, Duplicates, Invalid Formats)\n",
        "def identify_issues(df):\n",
        "    print(\"\\nIdentifying issues in the dataset:\")\n",
        "    print(\"\\nMissing or Empty Values:\")\n",
        "    print(df.replace({\"\": np.nan, \" \": np.nan, \"Unknown\": np.nan}).isnull().sum())\n",
        "    print(\"\\nDuplicate Entries:\")\n",
        "    print(df.duplicated().sum())\n",
        "    print(\"\\nData Types of Columns:\")\n",
        "    print(df.dtypes)\n",
        "\n",
        "# Step 3: Standardize Date Formats\n",
        "def standardize_date(date):\n",
        "    \"\"\"Standardizes date formats to a uniform format.\"\"\"\n",
        "    try:\n",
        "        return pd.to_datetime(date, errors='coerce', dayfirst=True)\n",
        "    except Exception as e:\n",
        "        return np.nan\n",
        "\n",
        "# Step 4: Convert columns to numeric values (and handle errors)\n",
        "def enforce_numeric(column):\n",
        "    \"\"\"Converts column values to numeric, coercing errors to NaN.\"\"\"\n",
        "    return pd.to_numeric(column, errors='coerce')\n",
        "\n",
        "# Step 5: Clean the data (automated)\n",
        "def clean_data(df):\n",
        "    \"\"\"Automatically cleans the dataset by fixing common issues.\"\"\"\n",
        "\n",
        "    # Replace empty strings, spaces, and 'Unknown' with NaN\n",
        "    df.replace({\"\": np.nan, \" \": np.nan, \"Unknown\": np.nan}, inplace=True)\n",
        "\n",
        "    # Convert 'Age' column to numeric and fill missing values with median\n",
        "    df['Age'] = enforce_numeric(df['Age'])\n",
        "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "    # Drop rows where 'Name' is missing\n",
        "    df.dropna(subset=['Name'], inplace=True)\n",
        "\n",
        "    # Drop duplicate rows\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Standardize 'Join Date' column to datetime format\n",
        "    df['Join Date'] = df['Join Date'].apply(standardize_date)\n",
        "\n",
        "    # Convert 'ID' column to numeric (nullable integer type)\n",
        "    df['ID'] = enforce_numeric(df['ID']).astype('Int64')\n",
        "\n",
        "    return df\n",
        "\n",
        "# Step 6: Automate the whole process\n",
        "def automate_data_cleaning(df):\n",
        "    \"\"\"Runs the entire cleaning process automatically.\"\"\"\n",
        "    print(\"Original Data Sample:\")\n",
        "    print(df.head())  # Show original data\n",
        "    identify_issues(df)  # Identify initial issues\n",
        "    df_cleaned = clean_data(df)  # Clean the data\n",
        "    print(\"\\nCleaned Data Sample:\")\n",
        "    print(df_cleaned.head())  # Show cleaned data\n",
        "\n",
        "    # Optionally, save the cleaned data to a CSV file\n",
        "    df_cleaned.to_csv(\"cleaned_data.csv\", index=False)\n",
        "    print(\"\\nCleaned data saved to 'cleaned_data.csv'\")\n",
        "\n",
        "    return df_cleaned\n",
        "\n",
        "# Example usage (automatically generate messy data using Faker)\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate a messy dataset\n",
        "    df = generate_messy_data(num_records=100)\n",
        "\n",
        "    # Run the automated data cleaning pipeline\n",
        "    automate_data_cleaning(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SISdGM-NeSu1",
        "outputId": "ad4de587-ec08-46b6-c4d7-d674459dbb1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data Sample:\n",
            "    ID         Name      Age   Join Date\n",
            "0   15         None       20  01-07-1983\n",
            "1       Ashley Ruiz       34  30-10-1974\n",
            "2  NaN               Unknown  31-08-1985\n",
            "3                        NaN     Invalid\n",
            "4  NaN         None      NaN  2023-10-21\n",
            "\n",
            "Identifying issues in the dataset:\n",
            "\n",
            "Missing or Empty Values:\n",
            "ID           68\n",
            "Name         60\n",
            "Age          67\n",
            "Join Date    20\n",
            "dtype: int64\n",
            "\n",
            "Duplicate Entries:\n",
            "4\n",
            "\n",
            "Data Types of Columns:\n",
            "ID           object\n",
            "Name         object\n",
            "Age          object\n",
            "Join Date    object\n",
            "dtype: object\n",
            "\n",
            "Cleaned Data Sample:\n",
            "      ID            Name   Age  Join Date\n",
            "1   <NA>     Ashley Ruiz  34.0 1974-10-30\n",
            "5   <NA>     John Dennis  40.0 1999-02-27\n",
            "8     44     Alison Hall  40.0        NaT\n",
            "9   <NA>   Steven Carter  40.0        NaT\n",
            "10  <NA>  Michelle Lopez  29.0        NaT\n",
            "\n",
            "Cleaned data saved to 'cleaned_data.csv'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-841241a6f0e6>:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  print(df.replace({\"\": np.nan, \" \": np.nan, \"Unknown\": np.nan}).isnull().sum())\n",
            "<ipython-input-7-841241a6f0e6>:50: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df.replace({\"\": np.nan, \" \": np.nan, \"Unknown\": np.nan}, inplace=True)\n",
            "<ipython-input-7-841241a6f0e6>:36: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
            "  return pd.to_datetime(date, errors='coerce', dayfirst=True)\n",
            "<ipython-input-7-841241a6f0e6>:36: UserWarning: Parsing dates in %m/%d/%Y format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
            "  return pd.to_datetime(date, errors='coerce', dayfirst=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"cleaned_data.csv\")\n"
      ],
      "metadata": {
        "id": "kwz0AHH2fjNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}